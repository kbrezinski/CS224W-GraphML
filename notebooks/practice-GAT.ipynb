{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "practice-deep_encoders.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNhUO2xLagV9k+DtlI2pacJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kbrezinski/CS224W-GraphML/blob/main/notebooks/practice-GAT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "\n",
        "from platform import python_version\n",
        "print(python_version())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoPgxPsiEQan",
        "outputId": "88972842-eff5-438d-8f97-af772bccd2b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.11.0+cu113\n",
            "3.7.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fl1XYtbhC0_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da89141e-dad3-4340-eebf-e7e14b0e98a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 7.9 MB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 40.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 39.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 750 kB 48.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 407 kB 5.4 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-scatter torch-sparse \\\n",
        " torch-cluster torch-spline-conv torch-geometric \\\n",
        "-f https://data.pyg.org/whl/torch-1.11.0+cu113.html -q\n",
        "#!pip install ogb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from torch_geometric.data import Dataset, Data, Batch\n",
        "from torch_geometric.loader import ClusterData, NeighborLoader, DataLoader"
      ],
      "metadata": {
        "id": "ckAz8Il1-Hhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch_geometric.data.batch.Batch \n",
        "# -creates batch of disconencted graphs from list\n",
        "\n",
        "# torch_geometric.data.data.Data\n",
        "# -creates single graph object\n",
        "\n",
        "# torch_geometric.data.cluster.ClusterData/ClusterLoader\n",
        "# -group nodes into smaller subgraphs and load them in batches for faster computation\n",
        "\n",
        "# torch_geometric.data.sampler.NeighborSampler\n",
        "# -samples specific number of nodes in neighbor\n",
        "# -sample training nodes only using node_idx"
      ],
      "metadata": {
        "id": "Uzi9_i6YVrc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "rows = np.random.choice(100, 500)\n",
        "cols = np.random.choice(100, 500)\n",
        "\n",
        "data = dict(x = torch.rand((100, 16), dtype=torch.float), # 100 nodes, 16 features)\n",
        "            edge_index = torch.tensor([rows, cols]), # (2, 500) random edges\n",
        "            edge_attr = np.random.choice(3, 500), # 500 edges, choose from 0, 1 or 2\n",
        "            y = torch.rand(100).round().long(),\n",
        ")  \n",
        "\n",
        "os.makedirs('data/raw', exist_ok=True)\n",
        "\n",
        "with open('./data/g0.pickle', 'wb') as f:\n",
        "  pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "xIeTYcaxZJYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = Data(**data)\n",
        "g"
      ],
      "metadata": {
        "id": "aYuquo28X05S",
        "outputId": "fbb6a272-5e84-40e4-8bf4-c36af4576c24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[100, 16], edge_index=[2, 500], edge_attr=[500], y=[100])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create batch of graphs using from_data_list\n",
        "g2 = g\n",
        "batch = Batch().from_data_list([g, g2])"
      ],
      "metadata": {
        "id": "Ukp7LXvRaVpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cluster data in 5 partitions, loop through N/5 nodes and retrieve edges\n",
        "cluster = ClusterData(g, 5)\n",
        "for c in cluster:\n",
        "  print(c)\n",
        "  break"
      ],
      "metadata": {
        "id": "shlxJjFsbEut",
        "outputId": "d5dc4969-bcf1-4ced-ac9e-7b7391a29448",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[20, 16], edge_attr=[500], y=[20], edge_index=[2, 36])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing METIS partitioning...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for 4 nodes in the graph, sample (3 * 4), (10 * 40) neighbors for each iteration\n",
        "sampler = NeighborLoader(g, num_neighbors=[3, 10],\n",
        "                         batch_size=4, shuffle=False,\n",
        "                         input_nodes=None) #data.train_mask,)\n",
        "for s in sampler:\n",
        "  print(s)\n",
        "  break"
      ],
      "metadata": {
        "id": "E_AWuG-_bvDf",
        "outputId": "84893108-4d03-49c3-913a-13d2e8ef4b88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[54, 16], edge_index=[2, 64], edge_attr=[500], y=[54], batch_size=4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_geometric.transforms as transforms\n",
        "# torch_geometric.transforms - list of functions transformations for graphs\n",
        "# example transforms\n",
        "# pre-transform - does so once its downloaded\n",
        "# tranform - does so after its downloaded and retreived\n",
        "\n",
        "transform = transforms.Compose([\n",
        "            transforms.RandomNodeSplit('train_rest', num_val=50, num_test=50),\n",
        "            #transforms.TargetIndegree(),\n",
        "            #transforms.AddSelfLoops(),\n",
        "            #transforms.Constant(value=1.)\n",
        "])"
      ],
      "metadata": {
        "id": "nSvxqgNk1Zt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "class SampleDataset(Dataset):\n",
        "  def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
        "    super().__init__(root, transform, pre_transform, pre_filter)\n",
        "\n",
        "  @property\n",
        "  def raw_file_names(self):\n",
        "    return ['g0.pickle']\n",
        "    \n",
        "  @property\n",
        "  def processed_file_names(self):\n",
        "    return ['g0.pt']\n",
        "\n",
        "  def download(self):   \n",
        "    rows = np.random.choice(100, 500)\n",
        "    cols = np.random.choice(100, 500)\n",
        "\n",
        "    data = dict(x = torch.rand((100, 16), dtype=torch.float), # 100 nodes, 16 features)\n",
        "                edge_index = torch.tensor([rows, cols]), # (2, 500) random edges\n",
        "                edge_attr = np.random.choice(3, 500), # 500 edges, choose from 0, 1 or 2\n",
        "                y = torch.rand(100).round().long(),\n",
        "    )  \n",
        "\n",
        "    with open('data/raw/g0.pickle', 'wb') as f:\n",
        "      pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "  def process(self):\n",
        "\n",
        "    # create data object\n",
        "    for file_name in self.raw_file_names:\n",
        "      with open(os.path.join('data/raw', file_name), 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "        self.graph = Data(**data)\n",
        "\n",
        "        if self.pre_filter is not None:\n",
        "          continue\n",
        "\n",
        "        if self.pre_transform is not None:\n",
        "          self.graph = self.pre_transform(self.graph)\n",
        "\n",
        "      torch.save(self.graph, os.path.join('data/processed',  file_name.split('.')[0] + '.pt'))\n",
        "\n",
        "  def len(self):\n",
        "    return len(self.processed_file_names)\n",
        "\n",
        "  def get(self, idx):\n",
        "    return torch.load(os.path.join('data/processed', f'g{idx}.pt'))\n",
        "    \n",
        "dataset = SampleDataset(root='data', transform=transform, pre_transform=None)"
      ],
      "metadata": {
        "id": "KK9YFhZG-Po_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataloader = DataLoader(dataset, batch_size=1)\n",
        "\n",
        "data = next(iter(dataset))\n",
        "\n",
        "# for 4 nodes in the graph, sample (3 * 4), (10 * 40) neighbors for each iteration\n",
        "sampler = NeighborLoader(data, num_neighbors=[10] * 2,\n",
        "                         batch_size=2, shuffle=True,\n",
        "                         input_nodes=data.train_mask) # pass in training/validation mask"
      ],
      "metadata": {
        "id": "ms3LK_jW-iBb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "5cd1dcc9-ada9-4f7a-98d4-37581f15c3af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-03cdd888c5f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m sampler = NeighborLoader(data, num_neighbors=[10] * 2,\n\u001b[1;32m      7\u001b[0m                          \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                          input_nodes=data.train_mask) # pass in training/validation mask\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/loader/neighbor_loader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, num_neighbors, input_nodes, replace, directed, transform, neighbor_sampler, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         return super().__init__(get_input_node_indices(self.data, input_nodes),\n\u001b[0;32m--> 232\u001b[0;31m                                 collate_fn=self.neighbor_sampler, **kwargs)\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHeteroData\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[0;32m---> 98\u001b[0;31m                              \"value, but got num_samples={}\".format(self.num_samples))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in sampler:\n",
        "  print(i.test_mask.sum())"
      ],
      "metadata": {
        "id": "zz8VLXI9EUzH",
        "outputId": "b90c61ae-4fba-4c1f-9063-4109682cb28e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(18)\n",
            "tensor(24)\n",
            "tensor(16)\n",
            "tensor(15)\n",
            "tensor(24)\n",
            "tensor(20)\n",
            "tensor(17)\n",
            "tensor(19)\n",
            "tensor(19)\n",
            "tensor(11)\n",
            "tensor(24)\n",
            "tensor(27)\n",
            "tensor(22)\n",
            "tensor(24)\n",
            "tensor(23)\n",
            "tensor(25)\n",
            "tensor(20)\n",
            "tensor(15)\n",
            "tensor(21)\n",
            "tensor(20)\n",
            "tensor(23)\n",
            "tensor(14)\n",
            "tensor(20)\n",
            "tensor(32)\n",
            "tensor(18)\n",
            "tensor(19)\n",
            "tensor(27)\n",
            "tensor(21)\n",
            "tensor(30)\n",
            "tensor(31)\n",
            "tensor(21)\n",
            "tensor(14)\n",
            "tensor(25)\n",
            "tensor(23)\n",
            "tensor(28)\n",
            "tensor(30)\n",
            "tensor(22)\n",
            "tensor(29)\n",
            "tensor(20)\n",
            "tensor(33)\n",
            "tensor(23)\n",
            "tensor(12)\n",
            "tensor(18)\n",
            "tensor(18)\n",
            "tensor(18)\n",
            "tensor(12)\n",
            "tensor(19)\n",
            "tensor(22)\n",
            "tensor(21)\n",
            "tensor(26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DPTkupXCZidO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}