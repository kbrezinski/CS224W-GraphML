{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "practice-deep_encoders.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPCNsneU8V7NJouMkKF5r/F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kbrezinski/CS224W-GraphML/blob/main/notebooks/practice_deep_encoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "\n",
        "from platform import python_version\n",
        "print(python_version())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoPgxPsiEQan",
        "outputId": "88972842-eff5-438d-8f97-af772bccd2b4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.11.0+cu113\n",
            "3.7.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fl1XYtbhC0_T",
        "outputId": "da89141e-dad3-4340-eebf-e7e14b0e98a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 7.9 MB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 40.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 39.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 750 kB 48.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 407 kB 5.4 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-scatter torch-sparse \\\n",
        " torch-cluster torch-spline-conv torch-geometric \\\n",
        "-f https://data.pyg.org/whl/torch-1.11.0+cu113.html -q\n",
        "#!pip install ogb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from torch_geometric.data import Dataset, Data, Batch\n",
        "from torch_geometric.loader import ClusterData, NeighborLoader, DataLoader"
      ],
      "metadata": {
        "id": "ckAz8Il1-Hhj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch_geometric.data.batch.Batch \n",
        "# -creates batch of disconencted graphs from list\n",
        "\n",
        "# torch_geometric.data.data.Data\n",
        "# -creates single graph object\n",
        "\n",
        "# torch_geometric.data.cluster.ClusterData/ClusterLoader\n",
        "# -group nodes into smaller subgraphs and load them in batches for faster computation\n",
        "\n",
        "# torch_geometric.data.sampler.NeighborSampler\n",
        "# -samples specific number of nodes in neighbor\n",
        "# -sample training nodes only using node_idx"
      ],
      "metadata": {
        "id": "Uzi9_i6YVrc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "rows = np.random.choice(100, 500)\n",
        "cols = np.random.choice(100, 500)\n",
        "\n",
        "data = dict(x = torch.rand((100, 16), dtype=torch.float), # 100 nodes, 16 features)\n",
        "            edge_index = torch.tensor([rows, cols]), # (2, 500) random edges\n",
        "            edge_attr = np.random.choice(3, 500), # 500 edges, choose from 0, 1 or 2\n",
        "            y = torch.rand(100).round().long(),\n",
        ")  \n",
        "\n",
        "os.makedirs('data/raw', exist_ok=True)\n",
        "\n",
        "with open('./data/g0.pickle', 'wb') as f:\n",
        "  pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "xIeTYcaxZJYa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = Data(**data)\n",
        "g"
      ],
      "metadata": {
        "id": "aYuquo28X05S",
        "outputId": "fbb6a272-5e84-40e4-8bf4-c36af4576c24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[100, 16], edge_index=[2, 500], edge_attr=[500], y=[100])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create batch of graphs using from_data_list\n",
        "g2 = g\n",
        "batch = Batch().from_data_list([g, g2])"
      ],
      "metadata": {
        "id": "Ukp7LXvRaVpm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cluster data in 5 partitions, loop through N/5 nodes and retrieve edges\n",
        "cluster = ClusterData(g, 5)\n",
        "for c in cluster:\n",
        "  print(c)\n",
        "  break"
      ],
      "metadata": {
        "id": "shlxJjFsbEut",
        "outputId": "d5dc4969-bcf1-4ced-ac9e-7b7391a29448",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[20, 16], edge_attr=[500], y=[20], edge_index=[2, 36])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing METIS partitioning...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for 4 nodes in the graph, sample (3 * 4), (10 * 40) neighbors for each iteration\n",
        "sampler = NeighborLoader(g, num_neighbors=[3, 10],\n",
        "                         batch_size=4, shuffle=False,\n",
        "                         input_nodes=None) #data.train_mask,)\n",
        "for s in sampler:\n",
        "  print(s)\n",
        "  break"
      ],
      "metadata": {
        "id": "E_AWuG-_bvDf",
        "outputId": "84893108-4d03-49c3-913a-13d2e8ef4b88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[54, 16], edge_index=[2, 64], edge_attr=[500], y=[54], batch_size=4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_geometric.transforms as transforms\n",
        "# torch_geometric.transforms - list of functions transformations for graphs\n",
        "# example transforms\n",
        "# pre-transform - does so once its downloaded\n",
        "# tranform - does so after its downloaded and retreived\n",
        "\n",
        "transform = transforms.Compose([\n",
        "            transforms.RandomNodeSplit('train_rest', num_val=50, num_test=50),\n",
        "            transforms.TargetIndegree(),\n",
        "])"
      ],
      "metadata": {
        "id": "nSvxqgNk1Zt3"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "class SampleDataset(Dataset):\n",
        "  def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
        "    super().__init__(root, transform, pre_transform, pre_filter)\n",
        "\n",
        "  @property\n",
        "  def raw_file_names(self):\n",
        "    return ['g0.pickle']\n",
        "    \n",
        "  @property\n",
        "  def processed_file_names(self):\n",
        "    return ['g0.pt']\n",
        "\n",
        "  def download(self):   \n",
        "    rows = np.random.choice(100, 500)\n",
        "    cols = np.random.choice(100, 500)\n",
        "\n",
        "    data = dict(x = torch.rand((100, 16), dtype=torch.float), # 100 nodes, 16 features)\n",
        "                edge_index = torch.tensor([rows, cols]), # (2, 500) random edges\n",
        "                edge_attr = np.random.choice(3, 500), # 500 edges, choose from 0, 1 or 2\n",
        "                y = torch.rand(100).round().long(),\n",
        "    )  \n",
        "\n",
        "    with open('data/raw/g0.pickle', 'wb') as f:\n",
        "      pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "  def process(self):\n",
        "\n",
        "    # create data object\n",
        "    for file_name in self.raw_file_names:\n",
        "      with open(os.path.join('data/raw', file_name), 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "        self.graph = Data(**data)\n",
        "\n",
        "        if self.pre_filter is not None:\n",
        "          continue\n",
        "\n",
        "        if self.pre_transform is not None:\n",
        "          self.graph = self.pre_transform(self.graph)\n",
        "\n",
        "      torch.save(self.graph, os.path.join('data/processed',  file_name.split('.')[0] + '.pt'))\n",
        "\n",
        "  def len(self):\n",
        "    return len(self.processed_file_names)\n",
        "\n",
        "  def get(self, idx):\n",
        "    return torch.load(os.path.join('data/processed', f'g{idx}.pt'))\n",
        "    \n",
        "dataset = SampleDataset(root='data', transform=None, pre_transform=None)"
      ],
      "metadata": {
        "id": "KK9YFhZG-Po_"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataloader = DataLoader(dataset, batch_size=1)\n",
        "\n",
        "data = next(iter(dataset))\n",
        "\n",
        "# for 4 nodes in the graph, sample (3 * 4), (10 * 40) neighbors for each iteration\n",
        "sampler = NeighborLoader(data, num_neighbors=[10] * 2,\n",
        "                         batch_size=16, shuffle=True,\n",
        "                         input_nodes=None) # pass in training/validation mask"
      ],
      "metadata": {
        "id": "ms3LK_jW-iBb"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in sampler:\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "zz8VLXI9EUzH",
        "outputId": "25ad14d7-291c-4de5-a729-123385e49810",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[93, 16], edge_index=[2, 270], edge_attr=[500], y=[93], batch_size=16)\n",
            "Data(x=[97, 16], edge_index=[2, 315], edge_attr=[500], y=[97], batch_size=16)\n",
            "Data(x=[96, 16], edge_index=[2, 298], edge_attr=[500], y=[96], batch_size=16)\n",
            "Data(x=[97, 16], edge_index=[2, 324], edge_attr=[500], y=[97], batch_size=16)\n",
            "Data(x=[95, 16], edge_index=[2, 326], edge_attr=[500], y=[95], batch_size=16)\n",
            "Data(x=[95, 16], edge_index=[2, 287], edge_attr=[500], y=[95], batch_size=16)\n",
            "Data(x=[62, 16], edge_index=[2, 87], edge_attr=[500], y=[62], batch_size=4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DPTkupXCZidO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}